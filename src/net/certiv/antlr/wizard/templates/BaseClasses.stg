delimiters "%", "%"
import "Header.stg"

ConverterClass(packageName, grammarName, startRule) ::= <<
%stdHdr()%
package %packageName%.converter;

import java.io.ByteArrayInputStream;
import java.io.IOException;

import %packageName%.generator.IOProcessor;
import %packageName%.parser.LexerHelper;
import %packageName%.parser.%grammarName%TokenFactory;
import %packageName%.parser.%grammarName%ErrorListener;
import %packageName%.parser.gen.%grammarName%Lexer;
import %packageName%.parser.gen.%grammarName%Parser;
import %packageName%.util.Log;

import org.antlr.v4.runtime.ANTLRInputStream;
import org.antlr.v4.runtime.CommonTokenStream;
import org.antlr.v4.runtime.tree.ParseTree;
import org.antlr.v4.runtime.tree.ParseTreeWalker;

public class Converter {

	private IOProcessor processor;

	public Converter(IOProcessor processor) {
		super();
		this.processor = processor;
	}

	public String convert(String srcData) {
		return convert(srcData, new PhaseState());
	}

	public String convert(String srcData, PhaseState state) {
		String lastError = "<none>";
		try {
			lastError = "Failure in acquiring input stream.";
			ByteArrayInputStream is = new ByteArrayInputStream(srcData.getBytes());
			ANTLRInputStream input = new ANTLRInputStream(is);

			lastError = "Failure in generating lexer token stream.";
			%grammarName%Lexer lexer = new %grammarName%Lexer(input);
//			lexer.setLexerHelper(new LexerHelper());
			%grammarName%TokenFactory factory = new %grammarName%TokenFactory(input);
			lexer.setTokenFactory(factory);
			CommonTokenStream tokens = new CommonTokenStream(lexer);

			lastError = "Failure in parser production.";
			%grammarName%Parser parser = new %grammarName%Parser(tokens);
			parser.setTokenFactory(factory);
			parser.removeErrorListeners(); // remove ConsoleErrorListener
			parser.addErrorListener(new %grammarName%ErrorListener());
			// parser.setErrorHandler(new %grammarName%ParserErrorStrategy());
			ParseTree tree = parser.%startRule%();

			ParseTreeWalker walker = new ParseTreeWalker();

			lastError = "Failure in parse phase 1.";
			state.tokens = tokens;
			%grammarName%Phase01 phase01 = new %grammarName%Phase01(state, processor);
			phase01.collectComments(true);
			walker.walk(phase01, tree);

			lastError = "Failure in parse phase 2.";
			%grammarName%Phase02 phase02 = new %grammarName%Phase02(phase01, processor);
			walker.walk(phase02, tree);

			if (!%grammarName%Phase02.statusResolved) {
				Log.warn(this, "Failure to resolve source description");
				return "";
			}

			lastError = "Failure in parse phase 3.";
			%grammarName%Phase03 phase03 = new %grammarName%Phase03(phase02, processor);
			walker.walk(phase03, tree);
			Log.info(this, "Convertion complete.");
			
			Log.info(this, "Convertion complete.");
			return state.doc.toString();
			
		} catch (IOException e) {
			Log.error(this, lastError, e);
			return "";
		}
	}
}
>>

PhaseBaseClass(packageName, grammarName) ::= <<
%stdHdr()%
package %packageName%.converter;

import java.util.List;

import %packageName%.generator.IOProcessor;
import %packageName%.parser.gen.%grammarName%Lexer;
import %packageName%.parser.gen.%grammarName%ParserBaseListener;

import org.antlr.v4.runtime.ParserRuleContext;
import org.antlr.v4.runtime.tree.ParseTree;

public class %grammarName%PhaseBase extends %grammarName%ParserBaseListener {

	protected PhaseState state;
	protected IOProcessor processor;

	/**
	 * Constructor with phase transference
	 */
	public %grammarName%PhaseBase(PhaseState state, IOProcessor processor) {
		super();
		this.state = state;
		this.processor = processor;
	}

	public BaseDescriptor getDescriptor(ParseTree ctx) {
		return this.state.nodeContextMap.get(ctx);
	}

	public void setDescriptor(ParseTree ctx, BaseDescriptor ncd) {
		this.state.nodeContextMap.put(ctx, ncd);
	}

	public String childText(ParserRuleContext rc, int idx) {
		return rc.getChild(idx).getText();
	}

	public String commentLeft(ParserRuleContext rc) {
		int tdx = rc.getStart().getTokenIndex();
		if (tdx <= 0) return "";
		int jdx = tdx - 1;
		boolean onlyWS = true;
		boolean done = false;
		while (!done) {
			switch (this.state.tokens.get(jdx).getType()) {
				case %grammarName%Lexer.Comment:
				case %grammarName%Lexer.CommentLine:
					onlyWS = false;
				case %grammarName%Lexer.HorzWS:
				case %grammarName%Lexer.VertWS:
					if (jdx > 0) {
						jdx--;
					} else {
						done = true;
					}
					break;
				default:
					done = true;
			}
		}
		if (onlyWS) return "";
		if (this.state.commentMarkers.contains(jdx)) {
			return "";
		} else {
			this.state.commentMarkers.add(jdx);
		}

		StringBuilder sb = new StringBuilder();
		for (; jdx < tdx; jdx++) {
			sb.append(this.state.tokens.get(jdx).getText());
		}
		return sb.toString();
	}

	public String commentRight(ParserRuleContext rc) {
		int tdx = rc.getStop().getTokenIndex();
		int jdx = tdx + 1;
		boolean onlyWS = true;
		boolean done = false;
		while (!done) {
			switch (this.state.tokens.get(jdx).getType()) {
				case %grammarName%Lexer.CommentLine:
					onlyWS = false;
				case %grammarName%Lexer.HorzWS:
					jdx++;
					break;
				case %grammarName%Lexer.EOF:
					done = true;
					break;
				default:
					done = true;
			}
		}
		if (onlyWS) return "";
		if (this.state.commentMarkers.contains(jdx)) {
			return "";
		} else {
			this.state.commentMarkers.add(jdx);
		}

		StringBuilder sb = new StringBuilder();
		for (tdx++; tdx <= jdx; tdx++) {
			sb.append(this.state.tokens.get(tdx).getText());
		}
		return sb.toString();
	}

	/**
	 * Returns the qualified name after removal of the last 'dotted' segment.
	 * 
	 * @param qualifiedName
	 * @return
	 */
	public String removeTerminal(String qualifiedName) {
		int idx = qualifiedName.lastIndexOf('.');
		if (idx == -1) return qualifiedName;
		return qualifiedName.substring(0, idx);
	}

	public ParseTree nextPeer(ParserRuleContext ctx, int idx) {
		List<ParseTree> ctxs = ctx.children;
		if (idx + 1 < ctxs.size()) {
			return ctxs.get(idx + 1);
		}
		return null;
	}
}

>>


