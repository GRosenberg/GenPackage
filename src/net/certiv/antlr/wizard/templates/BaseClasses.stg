delimiters "%", "%"

ConverterClass(packageName, grammarName, startRule) ::= <<
package %packageName%.converter;

import java.io.File;
import java.io.FileInputStream;
import java.io.IOException;

import %packageName%.parser.gen.%grammarName%Lexer;
import %packageName%.parser.gen.%grammarName%Parser;
import %packageName%.util.Log;

import org.antlr.v4.runtime.ANTLRInputStream;
import org.antlr.v4.runtime.CommonTokenStream;
import org.antlr.v4.runtime.tree.ParseTree;
import org.antlr.v4.runtime.tree.ParseTreeWalker;
import org.apache.commons.io.FileUtils;

public class Converter {

	public Converter() {
		super();
	}

	public void convert(File srcFile, File dstFile) {
		String lastError = "<none>";
		Log.info(this, "Converting " + srcFile.getName() + " -> " + dstFile.getName());
		try {
			lastError = "Failure in acquiring input stream.";
			FileInputStream is = new FileInputStream(srcFile);
			ANTLRInputStream input = new ANTLRInputStream(is);

			lastError = "Failure in generating lexer token stream.";
			%grammarName%Lexer lexer = new %grammarName%Lexer(input);
			// %grammarName%TokenFactory factory = new %grammarName%TokenFactory(input);
			// lexer.setTokenFactory(factory);
			CommonTokenStream tokens = new CommonTokenStream(lexer);

			lastError = "Failure in parser production.";
			%grammarName%Parser parser = new %grammarName%Parser(tokens);
			// parser.setTokenFactory(factory);
			// parser.removeErrorListeners(); // remove ConsoleErrorListener
			// parser.addErrorListener(new %grammarName%ErrorListener());
			// parser.setErrorHandler(new %grammarName%ParserErrorStrategy());
			ParseTree tree = parser.metalSpec();

			ParseTreeWalker walker = new ParseTreeWalker();

			lastError = "Failure in parse phase 1.";
			%grammarName%Phase01 phase01 = new %grammarName%Phase01(tokens);
			phase01.collectComments(true);
			walker.walk(phase01, tree);

			lastError = "Failure in parse phase 2.";
			%grammarName%Phase02 phase02 = new %grammarName%Phase02(phase01);
			walker.walk(phase02, tree);

			lastError = "Failure in parse phase 3.";
			%grammarName%Phase03 phase03 = new %grammarName%Phase03(phase02);
			walker.walk(phase03, tree);

			lastError = "Failure in parse phase 6.";
			%grammarName%Phase06 phase06 = new %grammarName%Phase06(phase03);
			walker.walk(phase06, tree);

			lastError = "Failure in parse phase 10.";
			%grammarName%Phase10 phase10 = new %grammarName%Phase10(phase06);
			walker.walk(phase10, tree);

			lastError = "Failure in final report production.";
			FileUtils.write(dstFile, tree.toStringTree());
			Log.info(this, "Convertion complete.");
		} catch (IOException e) {
			Log.error(this, lastError, e);
		}
	}
}
>>

PhaseBaseClass(packageName, grammarName) ::= <<
package %packageName%.converter;

import java.util.ArrayList;

import %packageName%.parser.gen.%grammarName%Lexer;
import %packageName%.parser.gen.%grammarName%ParserBaseListener;

import org.antlr.v4.runtime.CommonTokenStream;
import org.antlr.v4.runtime.ParserRuleContext;
import org.antlr.v4.runtime.tree.ParseTree;
import org.antlr.v4.runtime.tree.ParseTreeProperty;

public class %grammarName%PhaseBase extends %grammarName%ParserBaseListener {

	/**
	 * Constructor for initial phase
	 */
	public %grammarName%PhaseBase(CommonTokenStream tokens) {
		super();
		BaseDescriptor.tokens = tokens;
		BaseDescriptor.nodeContextMap = new ParseTreeProperty<NodeContextDescriptor>();
		BaseDescriptor.commentMarkers = new ArrayList<Integer>();
	}

	/**
	 * Constructor for subsequent phases
	 */
	public %grammarName%PhaseBase() {
		super();
	}

	public BaseDescriptor getDescriptor(ParseTree ctx) {
		return BaseDescriptor.nodeContextMap.get(ctx);
	}

	public void setDescriptor(ParseTree ctx, BaseDescriptor ncd) {
		BaseDescriptor.nodeContextMap.put(ctx, ncd);
	}

	public String childText(ParserRuleContext<Token> rc, int idx) {
		return rc.getChild(idx).getText();
	}

	public String commentLeft(ParserRuleContext<Token> rc) {
		int tdx = rc.getStart().getTokenIndex();
		int jdx = tdx - 1;
		boolean onlyWS = true;
		boolean done = false;
		while (!done) {
			switch (tokens.get(jdx).getType()) {
				case %grammarName%Lexer.COMMENT:
				case %grammarName%Lexer.COMMENT_BLOCK:
					onlyWS = false;
				case %grammarName%Lexer.HWS:
				case %grammarName%Lexer.VWS:
					if (jdx > 0) {
						jdx--;
					} else {
						done = true;
					}
					break;
				default:
					done = true;
			}
		}
		if (onlyWS) return "";
		if (commentMarkers.contains(jdx)) {
			return "";
		} else {
			commentMarkers.add(jdx);
		}

		StringBuilder sb = new StringBuilder();
		for (; jdx < tdx; jdx++) {
			sb.append(tokens.get(jdx).getText());
		}
		return sb.toString();
	}

	public String commentRight(ParserRuleContext<Token> rc) {
		int tdx = rc.getStop().getTokenIndex();
		int jdx = tdx + 1;
		boolean onlyWS = true;
		boolean done = false;
		while (!done) {
			switch (tokens.get(jdx).getType()) {
				case %grammarName%Lexer.COMMENT_LINE:
					onlyWS = false;
				case %grammarName%Lexer.HWS:
					jdx++;
					break;
				case %grammarName%Lexer.EOF:
					done = true;
					break;
				default:
					done = true;
			}
		}
		if (onlyWS) return "";
		if (commentMarkers.contains(jdx)) {
			return "";
		} else {
			commentMarkers.add(jdx);
		}

		StringBuilder sb = new StringBuilder();
		for (tdx++; tdx <= jdx; tdx++) {
			sb.append(tokens.get(tdx).getText());
		}
		return sb.toString();
	}

	/**
	 * Returns the qualified name after removal of the last 'dotted' segment.
	 * 
	 * @param qualifiedName
	 * @return
	 */
	public String removeTerminal(String qualifiedName) {
		int idx = qualifiedName.lastIndexOf('.');
		if (idx == -1) return qualifiedName;
		return qualifiedName.substring(0, idx);
	}
}
>>
