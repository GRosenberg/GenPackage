delimiters "%", "%"
import "..\libs\Header.stg"

AbstractBaseClassCopyright() ::= <<
 * Copyright (c) 2008-2014 G Rosenberg.
 * 
>>

AbstractBaseClassContributor() ::= <<
 *		G Rosenberg - initial API and implementation
 * 
>>

AbstractBaseClassVersion() ::= <<
 * 		1.0 - 2014.03.26: First release level code
 * 		1.1 - 2014.08.26: Updates, add Tests support
 * 
>>

AbstractBaseClass(packageName, grammarName, startRule) ::= <<
%hdrBeg()%
%AbstractBaseClassCopyright()%
%epl()%
%hdrBlankLn()%
%hdrContribPrefix()%
%AbstractBaseClassContributor()%
%hdrBlankLn()%
%hdrVersionPrefix()%
%AbstractBaseClassVersion()%
%hdrBlankLn()%
%hdrEnd()%
package %packageName%.test.base;

import static org.testng.Assert.assertEquals;
import static org.testng.Assert.assertNotNull;
import static org.testng.Assert.assertTrue;

import java.io.File;
import java.util.ArrayList;
import java.util.HashSet;
import java.util.List;
import java.util.Set;
import java.util.StringTokenizer;

import org.antlr.v4.runtime.ANTLRInputStream;
import org.antlr.v4.runtime.CharStream;
import org.antlr.v4.runtime.CommonTokenStream;
import org.antlr.v4.runtime.IntStream;
import org.antlr.v4.runtime.Lexer;
import org.antlr.v4.runtime.ParserRuleContext;
import org.antlr.v4.runtime.Token;
import org.antlr.v4.runtime.atn.ATN;
import org.antlr.v4.runtime.atn.LexerATNSimulator;
import org.antlr.v4.runtime.dfa.DFA;
import org.antlr.v4.runtime.tree.ParseTree;
import org.antlr.v4.tool.Grammar;
import org.antlr.v4.tool.LexerGrammar;

import %packageName%.parser.gen.%grammarName%Parser;
import %packageName%.parser.gen.%grammarName%ParserBaseListener;
import %packageName%.util.Strings;

public abstract class AbstractBase {

	public static final String TAB = "\\t";
	public static final String EOL = System.getProperty("line.separator");
	public static final String PSEP = System.getProperty("path.separator");

	public String tmpdir = null;

	/** reset during setUp and set to true if we find a problem */
	protected boolean lastTestFailed = false;

	public void setUpTempDir() throws Exception { // new output dir for each test
		lastTestFailed = false; // hope for the best, but set to true in asserts that fail
		long time = System.currentTimeMillis();
		tmpdir = new File("/tmp", getClass().getSimpleName() + "-" + time).getAbsolutePath();
		mkdir(tmpdir);
	\}

	public void tearDownTempDir() throws Exception { // remove tmpdir if no error.
		if (!lastTestFailed) eraseTempDir();
	\}

	public String lexSource(String source, boolean sysout, boolean hidden) {
		return lexSource("", source, sysout, hidden);
	\}

	public String lexSource(String name, String source, boolean sysout, boolean hidden) {
		CommonTokenStream tokens = produceTokens(name, source);
		tokens.fill();
		StringBuilder sb = new StringBuilder();
		for (Token token : tokens.getTokens()) {
			if (token.getChannel() == 0 || hidden) {
				String txt = getTokenString(token);
				sb.append(txt + EOL);
				if (sysout) System.out.print("+ \\"" + txt.trim() + "\\" + EOL" + Strings.eol);
			\}
		\}
		return sb.toString();
	\}

	public CommonTokenStream produceTokens(String name, String data) {
		ANTLRInputStream is = new ANTLRInputStream(data);
		is.name = name;
		return createLexerStream(is);
	\}

	public abstract String getBaseDir();

	public abstract String getTestExt();

	public abstract CommonTokenStream createLexerStream(ANTLRInputStream is);

	public abstract String getTokenString(Token token);

	public List<String> getTokenTypes(LexerGrammar lg, ATN atn, CharStream input) {
		LexerATNSimulator interp = new LexerATNSimulator(atn, new DFA[] { new DFA(
				atn.modeToStartState.get(Lexer.DEFAULT_MODE)) \}, null);
		List<String> tokenTypes = new ArrayList<String>();
		int ttype;
		boolean hitEOF = false;
		do {
			if (hitEOF) {
				tokenTypes.add("EOF");
				break;
			\}
			int t = input.LA(1);
			ttype = interp.match(input, Lexer.DEFAULT_MODE);
			if (ttype == Token.EOF) {
				tokenTypes.add("EOF");
			\} else {
				tokenTypes.add(lg.typeToTokenList.get(ttype));
			\}

			if (t == IntStream.EOF) {
				hitEOF = true;
			\}
		\} while (ttype != Token.EOF);
		return tokenTypes;
	\}

	public ParseTree produceTree(CommonTokenStream tokens) {
		%grammarName%Parser parser = new %grammarName%Parser(tokens);
		return parser.%startRule%();
	\}

	protected void checkSymbols(Grammar g, String rulesStr, String allValidTokensStr) throws Exception {
		String[] typeToTokenName = g.getTokenNames();
		Set<String> tokens = new HashSet<String>();
		for (int i = 0; i < typeToTokenName.length; i++) {
			String t = typeToTokenName[i];
			if (t != null) {
				if (t.startsWith(Grammar.AUTO_GENERATED_TOKEN_NAME_PREFIX)) {
					tokens.add(g.getTokenDisplayName(i));
				\} else {
					tokens.add(t);
				\}
			\}
		\}

		// make sure expected tokens are there
		StringTokenizer st = new StringTokenizer(allValidTokensStr, ", ");
		while (st.hasMoreTokens()) {
			String tokenName = st.nextToken();
			assertTrue(g.getTokenType(tokenName) != Token.INVALID_TYPE,
					"token " + tokenName + " expected, but was undefined");
			tokens.remove(tokenName);
		\}
		// make sure there are not any others (other than <EOF> etc...)
		for (String tokenName : tokens) {
			assertTrue(g.getTokenType(tokenName) < Token.MIN_USER_TOKEN_TYPE,
					"unexpected token name " + tokenName);
		\}

		// make sure all expected rules are there
		st = new StringTokenizer(rulesStr, ", ");
		int n = 0;
		while (st.hasMoreTokens()) {
			String ruleName = st.nextToken();
			assertNotNull(g.getRule(ruleName, "rule " + ruleName + " expected"));
			n++;
		\}
		assertEquals(n, g.rules.size(), "number of rules mismatch; expecting " + n + "; found " + g.rules.size());
	\}

	protected void mkdir(String dir) {
		File f = new File(dir);
		f.mkdirs();
	\}

	protected void eraseTempDir() {
		File tmpdirF = new File(tmpdir);
		if (tmpdirF.exists()) {
			eraseFiles();
			tmpdirF.delete();
		\}
	\}

	protected void eraseFiles() {
		if (tmpdir == null) return;
		File tmpdirF = new File(tmpdir);
		String[] files = tmpdirF.list();
		for (int i = 0; files != null && i < files.length; i++) {
			new File(tmpdir + PSEP + files[i]).delete();
		\}
	\}

	public class ProcessEveryRule extends %grammarName%ParserBaseListener {

		@Override
		public void enterEveryRule(ParserRuleContext ctx) {
			super.enterEveryRule(ctx);
		\}

		@Override
		public void exitEveryRule(ParserRuleContext ctx) {
			super.exitEveryRule(ctx);
		\}
	\}
\}


>>

TestBaseClassCopyright() ::= <<
 * Copyright (c) 2008-2014 G Rosenberg.
 * 
>>

TestBaseClassContributor() ::= <<
 *		G Rosenberg - initial API and implementation
 * 
>>

TestBaseClassVersion() ::= <<
 * 		1.0 - 2014.03.26: First release level code
 * 		1.1 - 2014.08.26: Updates, add Tests support
 * 
>>

TestBaseClass(packageName, grammarName) ::= <<
%hdrBeg()%
%TestBaseClassCopyright()%
%epl()%
%hdrBlankLn()%
%hdrContribPrefix()%
%TestBaseClassContributor()%
%hdrBlankLn()%
%hdrVersionPrefix()%
%TestBaseClassVersion()%
%hdrBlankLn()%
%hdrEnd()%
package %packageName%.test.base;

import java.io.File;
import java.io.IOException;

import org.antlr.v4.runtime.ANTLRInputStream;
import org.antlr.v4.runtime.CommonTokenStream;
import org.antlr.v4.runtime.Token;
import org.antlr.v4.runtime.tree.ParseTreeWalker;

import %packageName%.IOProcessor;
import %packageName%.converter.Converter;
import %packageName%.converter.%grammarName%Phase01;
import %packageName%.converter.%grammarName%Phase02;
import %packageName%.converter.%grammarName%Phase03;
import %packageName%.converter.PhaseState;
import %packageName%.parser.%grammarName%ErrorListener;
import %packageName%.parser.%grammarName%Token;
import %packageName%.parser.%grammarName%TokenFactory;
import %packageName%.parser.gen.%grammarName%Lexer;
import %packageName%.parser.gen.%grammarName%Parser;
import %packageName%.parser.gen.%grammarName%Parser.%grammarName%Context;
import %packageName%.util.FileUtils;
import %packageName%.util.Log;

public class TestBase extends AbstractBase {

	public static final String DataDir = "test.data";
	public static final String ResultDir = "test.results";
	public static final String LexExt = "Lex.txt";
	public static final String ParseExt = "Parse.txt";

	public TestBase() {
		super();
		Log.setTestMode(true);
	\}

	@Override
	public String getBaseDir() {
		return null;
	\}

	@Override
	public String getTestExt() {
		return null;
	\}

	@Override
	public String getTokenString(Token token) {
		return ((%grammarName%Token) token).toString();
	\}

	@Override
	public CommonTokenStream createLexerStream(ANTLRInputStream is) {
		%grammarName%Lexer lexer = new %grammarName%Lexer(is);
		%grammarName%TokenFactory factory = new %grammarName%TokenFactory(is);
		lexer.setTokenFactory(factory);
		return new CommonTokenStream(lexer);
	\}

	public String produceTree(CommonTokenStream tokens, boolean sysout) {
		PhaseState state = new PhaseState();
		state.tokens = tokens;

		%grammarName%Parser parser = new %grammarName%Parser(tokens);
		parser.removeErrorListeners();
		parser.addErrorListener(new %grammarName%ErrorListener());
		%grammarName%Context tree = parser.json();
		ParseTreeWalker walker = new ParseTreeWalker();

		Converter conv = new Converter(new IOProcessor(new String[] { "-s" \}));
		%grammarName%Phase01 phase01 = conv.processPhase01(tree, walker, state);
		%grammarName%Phase02 phase02 = conv.processPhase02(tree, walker, phase01);
		%grammarName%Phase03 phase03 = conv.processPhase03(tree, walker, phase02);

		String result = phase03.getState().doc.toString();
		if (sysout) System.out.println(result);
		return result;
	\}

	public String readSrcString(String name) {
		return readString(DataDir, name, getTestExt());
	\}

	public String readUpdateLexString(String name, String found) {
		String expecting = readString(ResultDir, name, LexExt);
		if (expecting.length() == 0) {
			writeString(ResultDir, name, found, LexExt);
		\}
		return expecting;
	\}

	public String readUpdateParseTree(String name, String found) {
		String expecting = readString(ResultDir, name, ParseExt);
		if (expecting.length() == 0) {
			writeString(ResultDir, name, found, ParseExt);
		\}
		return expecting;
	\}

	private String readString(String dir, String name, String ext) {
		name = convertName(dir, name, ext);
		File f = new File(name);
		String data = "";
		if (f.isFile()) {
			try {
				data = FileUtils.read(f);
			\} catch (IOException e) {
				System.err.println("Read failed: " + e.getMessage());
			\}
		\}
		return data;
	\}

	private void writeString(String dir, String name, String data, String ext) {
		name = convertName(dir, name, ext);
		File f = new File(name);
		File p = f.getParentFile();
		if (!p.exists()) {
			if (!p.mkdirs()) {
				System.err.println("Failed to create directory: " + p.getAbsolutePath());
				return;
			\}
		\} else if (p.isFile()) {
			System.err.println("Cannot make directory: " + p.getAbsolutePath());
			return;
		\}

		if (f.exists() && f.isFile()) {
			f.delete();
		\}
		try {
			FileUtils.write(f, data, false);
		\} catch (IOException e) {
			System.err.println("Write failed: " + e.getMessage());
		\}
	\}

	private String convertName(String dir, String name, String ext) {
		int idx = name.lastIndexOf('.');
		if (idx > 0) {
			name = name.substring(0, idx);
		\}
		return FileUtils.concat(getBaseDir(), dir, name + ext);
	\}
\}

>>

TestWordClassCopyright() ::= <<
 * Copyright (c) 2008-2014 G Rosenberg.
 * 
>>

TestWordClassContributor() ::= <<
 *		G Rosenberg - initial API and implementation
 * 
>>

TestWordClassVersion() ::= <<
 * 		1.0 - 2014.03.26: First release level code
 * 		1.1 - 2014.08.26: Updates, add Tests support
 * 
>>

TestWordClass(packageName, grammarName) ::= <<
%hdrBeg()%
%TestWordClassCopyright()%
%epl()%
%hdrBlankLn()%
%hdrContribPrefix()%
%TestWordClassContributor()%
%hdrBlankLn()%
%hdrVersionPrefix()%
%TestWordClassVersion()%
%hdrBlankLn()%
%hdrEnd()%
package %packageName%.test;

import static org.testng.Assert.assertEquals;

import org.testng.annotations.AfterMethod;
import org.testng.annotations.BeforeMethod;
import org.testng.annotations.Test;

import %packageName%.IOProcessor;
import %packageName%.converter.Converter;
import %packageName%.test.base.TestBase;
import %packageName%.util.Log;

public class TestWord extends TestBase {

	private Converter converter;

	@BeforeMethod
	public void setUp() throws Exception {
		Log.setTestMode(true);
		String[] args = { "-s" \};
		IOProcessor processor = new IOProcessor(args);
		converter = new Converter(processor);
	\}

	@AfterMethod
	public void tearDown() throws Exception {
		converter = null;
	\}

	@Test
	public void testLexBold() throws Exception {
		String source = "This is a *simple* sentence." + EOL;
		String found = lexSource(source, true, true);
		String expecting = "[@0   1:0  Word='This' ]" + EOL
				+ "[@1   1:4  Ws=' ' Hidden]" + EOL
				+ "[@2   1:5  Word='is' ]" + EOL
				+ "[@3   1:7  Ws=' ' Hidden]" + EOL
				+ "[@4   1:8  Word='a' ]" + EOL
				+ "[@5   1:9  Ws=' ' Hidden]" + EOL
				+ "[@6   1:10 Star='*' ]" + EOL
				+ "[@7   1:11 Word='simple' ]" + EOL
				+ "[@8   1:17 Star='*' ]" + EOL
				+ "[@9   1:18 Ws=' ' Hidden]" + EOL
				+ "[@10  1:19 Word='sentence.' ]" + EOL
				+ "[@11  1:28 Blankline='rn' ]" + EOL//
				+ "[@12  2:30 Eof='<EOF>' ]" + EOL;
		assertEquals(found, expecting);
	\}

	@Test
	public void testConvertBold() {
		String source = "This is a *simple* sentence." + EOL;
		String result = converter.convert("", source);
		String expecting = "<p>This is a <b>simple</b> sentence.</p>" + EOL;
		assertEquals(expecting, result);
	\}

	@Test
	public void testLexUnderscore() throws Exception {
		String source = "Test: _underline_ text." + EOL;
		String found = lexSource(source, true, true);
		String expecting = "[@0   1:0  Word='Test:' ]" + EOL
				+ "[@1   1:5  Ws=' ' Hidden]" + EOL
				+ "[@2   1:6  Underscore='_' ]" + EOL
				+ "[@3   1:7  Word='underline' ]" + EOL
				+ "[@4   1:16 Underscore='_' ]" + EOL
				+ "[@5   1:17 Ws=' ' Hidden]" + EOL
				+ "[@6   1:18 Word='text.' ]" + EOL
				+ "[@7   1:23 Blankline='rn' ]" + EOL
				+ "[@8   2:25 Eof='<EOF>' ]" + EOL;
		assertEquals(found, expecting);
	\}

	@Test
	public void testWordPunct() throws Exception {
		String source = "And, just_a simple-test. Here & now: a *'special'* don't." + EOL;
		String found = lexSource(source, true, true);
		String expecting = "[@0   1:0  Word='And,' ]" + EOL
				+ "[@1   1:4  Ws=' ' Hidden]" + EOL
				+ "[@2   1:5  Word='just_a' ]" + EOL
				+ "[@3   1:11 Ws=' ' Hidden]" + EOL
				+ "[@4   1:12 Word='simple-test.' ]" + EOL
				+ "[@5   1:24 Ws=' ' Hidden]" + EOL
				+ "[@6   1:25 Word='Here' ]" + EOL
				+ "[@7   1:29 Ws=' ' Hidden]" + EOL
				+ "[@8   1:30 Word='&' ]" + EOL
				+ "[@9   1:31 Ws=' ' Hidden]" + EOL
				+ "[@10  1:32 Word='now:' ]" + EOL
				+ "[@11  1:36 Ws=' ' Hidden]" + EOL
				+ "[@12  1:37 Word='a' ]" + EOL
				+ "[@13  1:38 Ws=' ' Hidden]" + EOL
				+ "[@14  1:39 Star='*' ]" + EOL
				+ "[@15  1:40 SQuote=''' ]" + EOL
				+ "[@16  1:41 Word='special' ]" + EOL
				+ "[@17  1:48 SQuote=''' ]" + EOL
				+ "[@18  1:49 Star='*' ]" + EOL
				+ "[@19  1:50 Ws=' ' Hidden]" + EOL
				+ "[@20  1:51 Word='don't.' ]" + EOL
				+ "[@21  1:57 Blankline='rn' ]" + EOL
				+ "[@22  2:59 Eof='<EOF>' ]" + EOL;
		assertEquals(found, expecting);
	\}
\}


>>

TestBulkClassCopyright() ::= <<
 * Copyright (c) 2008-2014 G Rosenberg.
 * 
>>

TestBulkClassContributor() ::= <<
 *		G Rosenberg - initial API and implementation
 * 
>>

TestBulkClassVersion() ::= <<
 * 		1.0 - 2014.03.26: First release level code
 * 		1.1 - 2014.08.26: Updates, add Tests support
 * 
>>

TestBulkClass(packageName, grammarName) ::= <<
%hdrBeg()%
%TestBulkClassCopyright()%
%epl()%
%hdrBlankLn()%
%hdrContribPrefix()%
%TestBulkClassContributor()%
%hdrBlankLn()%
%hdrVersionPrefix()%
%TestBulkClassVersion()%
%hdrBlankLn()%
%hdrEnd()%
package %packageName%.bulk;

import java.io.File;

import %packageName%.util.Log;
import %packageName%.util.Log.LogLevel;

public class TestBulk {

	public TestBulk() {\}

	private TestIOProcessor processor;

	public static void main(String[] args) {
		new TestBulk(args);
	\}

	public TestBulk(String[] args) {

		Log.defLevel(LogLevel.Debug);
		Log.setTestMode(false);

		if (args == null || args.length == 0) {
			String input = "D:/DevFiles/Java/Workspaces/Main/net.certiv.antlr.go/src/org/antlr/v4/runtime";
			args = new String[] { "-i", input, "-t", "java", "-e", "200" \};
		\}

		Log.info(this, "TestBulk running...");
		processor = new TestIOProcessor(args);
		File root = processor.init();
		if (root != null) {
			Log.info(this, "Startup complete.");

			int beg = processor.getBeg();
			int end = processor.getEnd();
			processor.processFiles(root, beg, end);

			Log.info(this, "Done.");
		\} else {
			Log.error(this, "TestBulk Failed.");
		\}
	\}
\}


>>

TestIOProcessorClassCopyright() ::= <<
 * Copyright (c) 2008-2014 G Rosenberg.
 * 
>>

TestIOProcessorClassContributor() ::= <<
 *		G Rosenberg - initial API and implementation
 * 
>>

TestIOProcessorClassVersion() ::= <<
 * 		1.0 - 2014.03.26: First release level code
 * 		1.1 - 2014.08.26: Updates, add Tests support
 * 
>>

TestIOProcessorClass(packageName, grammarName) ::= <<
%hdrBeg()%
%TestIOProcessorClassCopyright()%
%epl()%
%hdrBlankLn()%
%hdrContribPrefix()%
%TestIOProcessorClassContributor()%
%hdrBlankLn()%
%hdrVersionPrefix()%
%TestIOProcessorClassVersion()%
%hdrBlankLn()%
%hdrEnd()%
package %packageName%.bulk;

import java.io.File;
import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.util.ArrayList;

import org.antlr.v4.runtime.ANTLRFileStream;
import org.antlr.v4.runtime.CommonTokenStream;
import org.antlr.v4.runtime.RecognitionException;
import org.apache.commons.io.FileUtils;
import org.apache.commons.io.IOUtils;

import %packageName%.parser.%grammarName%ErrorListener;
import %packageName%.parser.%grammarName%TokenFactory;
import %packageName%.parser.gen.%grammarName%Lexer;
import %packageName%.parser.gen.%grammarName%Parser;
import %packageName%.parser.gen.%grammarName%Parser.%grammarName%Context;
import %packageName%.util.Log;
import %packageName%.util.Log.LogLevel;

public class TestIOProcessor {

	private String[] opts; // pathnames
	private String source; // processed pathnames
	private String target;

	private ArrayList<String> types = new ArrayList<>();

	private boolean FileIn; // flags
	private boolean FileOut;
	private boolean StdIO;
	private boolean TextIn;

	private String srcData; // loaded source data
	private int beg = 0;
	private int end = 100;

	public TestIOProcessor(String[] args) {
		Log.setLevel(this, LogLevel.Debug);
		if (args.length == 0) {
			printHelp();
		\}
		opts = new String[3];
		opts[0] = opts[1] = opts[2] = "";
		for (int idx = 0; idx < args.length; idx++) {

			switch (args[idx].trim().toLowerCase()) {
				case "-b":
					idx++;
					beg = Integer.parseInt(args[idx]);
					break;
				case "-e":
					idx++;
					end = Integer.parseInt(args[idx]);
					break;
				case "-t":
					idx++;
					types.add(args[idx]);
					break;
				case "-i":
					idx++;
					source = args[idx];
					break;
				case "-h":
				default:
					printHelp();
					break;
			\}
		\}
	\}

	public File init() {
		if (source == null) {
			Log.error(this, "Need to specify an input source.");
			return null;
		\}

		File root = new File(source);
		if (!root.exists()) {
			Log.error(this, "Source file does not exist (" + source + ")");
			return null;
		\}

		return root;
	\}

	public String getSourceName() {
		return source;
	\}

	public String loadData() {
		if (FileIn) {
			String msg = "Error reading source data from file '" + source + "'";
			try {
				srcData = FileUtils.readFileToString(new File(source));
			\} catch (IOException e) {
				Log.error(this, msg);
			\}
		\} else if (StdIO && !TextIn) {
			String msg = "Error reading source data from standard in";
			InputStream in = System.in;
			try {
				srcData = IOUtils.toString(System.in);
			\} catch (IOException e) {
				Log.error(this, msg);
			\} finally {
				IOUtils.closeQuietly(in);
			\}
		\} else if (TextIn) {
			StdIO = true;
		\}
		return srcData;
	\}

	public void storeData(String data) {
		if (FileOut) {
			try {
				FileUtils.writeStringToFile(new File(target), data);
			\} catch (IOException e) {
				Log.error(this, "Error writing result data to file '" + target + "'", e);
			\}
		\} else if (StdIO) {
			OutputStream out = System.out;
			try {
				IOUtils.write(data, out);
			\} catch (IOException e) {
				Log.error(this, "Error writing result data to standard out", e);
			\} finally {
				IOUtils.closeQuietly(out);
			\}
		\}
	\}

	public void processFiles(File root, int begin, int end) {
		int count = 0;
		int passed = 0;
		if (root.isFile() && end > 0) {
			evaluateFile(root);
		\} else if (root.isDirectory()) {
			String[] checkedTypes = getCheckedTypes();
			for (File file : FileUtils.listFiles(root, checkedTypes, true)) {
				count++;
				if (count >= begin) {
					Log.debug(this, "Processing (" + count + ") " + file.getPath());
					passed += evaluateFile(file);
				\} else {
					Log.debug(this, "Skipping (" + count + ") " + file.getPath());
				\}
				if (count >= end) break;
			\}
		\}
		Log.info(this, "Processed " + count + "/" + passed + " files/passed.");

	\}

	private int evaluateFile(File file) {

		String lastError = "Failure in acquiring input stream.";
		%grammarName%Context result = null;
		try {
			ANTLRFileStream input = new ANTLRFileStream(file.getPath());
			input.name = file.getName();

			lastError = "Failure in generating lexer token stream.";
			%grammarName%Lexer lexer = new %grammarName%Lexer(input);
			%grammarName%TokenFactory factory = new %grammarName%TokenFactory(input);
			lexer.setTokenFactory(factory);
			CommonTokenStream tokens = new CommonTokenStream(lexer);

			lastError = "Failure in parser production.";
			%grammarName%Parser parser = new %grammarName%Parser(tokens);
			parser.setTokenFactory(factory);
			parser.removeErrorListeners(); // remove ConsoleErrorListener
			parser.addErrorListener(new %grammarName%ErrorListener());
			// parser.addErrorListener(new DiagnosticErrorListener());
			// parser.setErrorHandler(new %grammarName%ParserErrorStrategy());
			result = parser.json();
		\} catch (RecognitionException | IOException e) {
			Log.error(this, file.getName() + ": " + lastError);
			return 0;
		\}
		if (result != null && result.getChildCount() > 0) {
			return 1;
		\}
		return 0;
	\}

	private String[] getCheckedTypes() {
		int num = types.size();
		return types.toArray(new String[num]);
	\}

	public int getBeg() {
		return beg;
	\}

	public int getEnd() {
		return end;
	\}

	@SuppressWarnings("unused")
	private String cwd() {
		String cwd = "";
		try {
			cwd = new File(".").getCanonicalPath();
		\} catch (IOException e) {\}
		return cwd;
	\}

	@SuppressWarnings("unused")
	private String readFile(String filename) {
		File file = new File(filename);
		String data = null;
		try {
			data = FileUtils.readFileToString(file);
		\} catch (IOException e) {
			Log.error(this, "Error reading file", e);
		\}
		return data;

	\}

	private void printHelp() {
		System.out.println("Usage:");
		System.out.println("java -jar [cli_options]" + System.lineSeparator());
		// etc.
		System.exit(0);
	\}
\}


>>
